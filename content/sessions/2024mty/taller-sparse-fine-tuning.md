---
title: "Taller: Aplicando Sparse Fine-Tuning a las capas de multihead attention en LLMs"
slug: taller-sparse-fine-tuning
speakers:
 - jose-carlos-castro-montes
time_start: 2024-11-05T17:20:00
time_end:   2024-11-05T18:40:00
day: 2024mty
timeslot: 39
gridarea: "16/3/18/4"
room: Sala 2
track: Data science
tags:
slides: 
video: 
---

El Sparse fine-tuning de mecanismos de atención se utiliza para optimizar LLMs y sean mas precisos en tareas o contextos especificos. Este taller profundiza en los principios teoricos y la práctica de aplicar técnicas de sparse fine-tuning a las attention layers de los LLMs, con el objetivo de reducir los costos computacionales del fine tuning total manteniendo el rendimiento del modelo en las tareas que se quieren optimizar. Los participantes obtendrán una comprensión integral de las metodologías de sparse fine-tuning, experiencia práctica implementando estas técnicas en modelos populares y conocimientos sobre cómo evaluar la eficacia de los modelos sparse fine-tuned. A través de una combinación de explicaciones teóricas y demostraciones prácticas.
