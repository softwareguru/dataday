---
title: "Superando las limitaciones de los sistemas de ML a gran escala"
slug: superando-limitaciones
speakers:
 - Basilio Karamanos
time_start: 2024-11-05T17:20:00
time_end:   2024-11-05T18:00:00
day: 2024mty
timeslot: 39
gridarea: "16/3/17/4"
room: Sala 2
track: Data science
---

Los sistemas de aprendizaje de gran escala, como los modelos de lenguaje grande (LLMs) y las redes neuronales profundas tradicionales, han impulsado avances significativos en inteligencia artificial. Sin embargo, estos sistemas enfrentan desafíos críticos en términos de interpretabilidad, responsabilidad, justicia y eficiencia en el consumo de energía. Esta charla explorará cómo las Redes Neuronales Líquidas (Liquid Neural Networks) emergen como una solución prometedora para superar estas limitaciones.

Basándonos en investigaciones recientes, incluyendo el trabajo realizado en el CSAIL MIT, analizaremos cómo las Redes Neuronales Líquidas abordan los siguientes aspectos:

•	Interpretabilidad: Cómo la naturaleza dinámica y adaptable de estas redes permite una mejor comprensión de sus procesos de toma de decisiones.
•	Responsabilidad: El potencial de las Redes Neuronales Líquidas para proporcionar resultados más trazables y justificables.
•	Justicia: Cómo su arquitectura flexible puede ayudar a mitigar sesgos inherentes en los datos de entrenamiento.
•	Eficiencia Energética: La capacidad de estas redes para operar con menos parámetros y menor consumo computacional.

Exploraremos casos de uso prácticos, demostrando cómo las Redes Neuronales Líquidas pueden ofrecer soluciones más robustas y eficientes que los modelos tradicionales.

Esta charla proporcionará a los asistentes una idea de esta tecnología emergente y su potencial para revolucionar el campo del ML/AI. Los participantes obtendrán intuición sobre cómo las Redes Neuronales Líquidas pueden aplicarse para construir sistemas de IA más interpretables, responsables, justos y energéticamente eficientes, preparándolos para la próxima generación de soluciones de inteligencia artificial.